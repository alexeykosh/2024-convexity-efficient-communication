{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "import math\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "NOISE = 1e-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of Convexity: [0.8432291666666667, 0.8432291666666667, 0.8381696428571428, 0.7885416666666667, 0.8402777777777777]\n"
     ]
    }
   ],
   "source": [
    "def point_in_hull(point, hull):\n",
    "    '''\n",
    "    Check if a point is inside the convex hull.\n",
    "    '''\n",
    "    return all((np.dot(eq[:-1], point) + eq[-1] <= 0) for eq in hull.equations)\n",
    "\n",
    "def degree_of_convexity_cluster(cluster_points):\n",
    "    '''\n",
    "    Build the convex hull around cluster. \n",
    "    Find the number of points in the hull. \n",
    "    Divide the number of points in the class \n",
    "    by the number of points inside the hull\n",
    "    '''\n",
    "    if len(cluster_points) < 4:\n",
    "        return 1\n",
    "    else:\n",
    "        hull = ConvexHull(cluster_points)\n",
    "        in_hull = [p for p in cluster_points if point_in_hull(p, hull)]\n",
    "        return len(in_hull) / (len(cluster_points) + 1)\n",
    "\n",
    "def degree_of_convexity(arrays):\n",
    "    '''Compute the degree of convexity for the given array or arrays'''\n",
    "    convexity_list = []\n",
    "    for arr in arrays:\n",
    "        labels = np.unique(arr)  # Get unique labels\n",
    "        convexities = [degree_of_convexity_cluster(np.argwhere(arr == label)) for label in labels]\n",
    "        weights = [np.sum(arr == label) for label in labels]\n",
    "        convexity = np.average(convexities, weights=weights)\n",
    "        convexity_list.append(convexity)\n",
    "    return convexity_list\n",
    "\n",
    "# Given arrays\n",
    "arrays = np.array([[[2, 2, 2, 0],\n",
    "                    [1, 0, 0, 2],\n",
    "                    [0, 2, 2, 1],\n",
    "                    [0, 1, 1, 2]],\n",
    "\n",
    "                   [[1, 2, 1, 0],\n",
    "                    [2, 0, 2, 2],\n",
    "                    [2, 0, 1, 0],\n",
    "                    [2, 1, 1, 2]],\n",
    "\n",
    "                   [[1, 2, 2, 2],\n",
    "                    [1, 2, 1, 1],\n",
    "                    [1, 2, 0, 0],\n",
    "                    [2, 2, 0, 1]],\n",
    "\n",
    "                   [[0, 1, 2, 0],\n",
    "                    [1, 2, 1, 1],\n",
    "                    [0, 2, 2, 1],\n",
    "                    [0, 1, 2, 1]],\n",
    "\n",
    "                   [[2, 1, 2, 2],\n",
    "                    [0, 2, 2, 1],\n",
    "                    [0, 2, 0, 0],\n",
    "                    [0, 2, 1, 2]]])\n",
    "\n",
    "convexities = degree_of_convexity(arrays)\n",
    "print(\"Degrees of Convexity:\", convexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_upper_bound(N, shape):\n",
    "    total_elements = np.prod(shape)\n",
    "    return min(N**total_elements, N ** max(0, total_elements - N + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lexicons(N, shape, n):\n",
    "    total_elements = np.prod(shape)\n",
    "    upper_bound = min(N**total_elements, N ** max(0, total_elements - N + 1))\n",
    "    lexicons = set()\n",
    "\n",
    "    while len(lexicons) < min(n, upper_bound):\n",
    "        lexicon = tuple(map(tuple, np.random.randint(0, N, shape)))\n",
    "        lexicons.add(lexicon)\n",
    "\n",
    "    return np.array([list(lexicon) for lexicon in lexicons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 3, 1],\n",
       "        [4, 5, 4],\n",
       "        [8, 8, 4]],\n",
       "\n",
       "       [[3, 4, 6],\n",
       "        [1, 7, 4],\n",
       "        [6, 8, 6]],\n",
       "\n",
       "       [[3, 1, 4],\n",
       "        [6, 4, 3],\n",
       "        [5, 7, 2]],\n",
       "\n",
       "       [[6, 0, 5],\n",
       "        [8, 0, 7],\n",
       "        [1, 6, 7]],\n",
       "\n",
       "       [[2, 3, 7],\n",
       "        [4, 4, 1],\n",
       "        [1, 5, 0]],\n",
       "\n",
       "       [[5, 4, 3],\n",
       "        [7, 8, 3],\n",
       "        [5, 8, 4]],\n",
       "\n",
       "       [[7, 8, 1],\n",
       "        [7, 2, 7],\n",
       "        [7, 1, 0]],\n",
       "\n",
       "       [[0, 5, 0],\n",
       "        [0, 2, 3],\n",
       "        [3, 3, 6]],\n",
       "\n",
       "       [[5, 8, 6],\n",
       "        [1, 1, 6],\n",
       "        [7, 7, 5]]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lexicons(9, (3, 3), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_lexicons(N, shape, n):\n",
    "#     # sample a shape numpy array with N integers n times\n",
    "#     return np.random.randint(0, N, (n, *shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRSA:\n",
    "    def __init__(self, alpha, prior):\n",
    "        self.alpha = alpha\n",
    "        self.prior = prior\n",
    "\n",
    "    @staticmethod\n",
    "    def safelog(vals):\n",
    "        with np.errstate(divide='ignore'):\n",
    "            return np.log(vals)\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalize(vals):\n",
    "        return np.nan_to_num(vals / np.sum(vals, axis=-1, keepdims=True))\n",
    "        \n",
    "    @staticmethod\n",
    "    def binary_language(L):\n",
    "        max_labels = np.max([np.max(subarray) for subarray in L]) + 1\n",
    "        binary_arrays = []\n",
    "        for subarray in L:\n",
    "            x = max_labels\n",
    "            y = np.prod(subarray.shape)\n",
    "            binary_array = np.zeros((x, y), dtype=np.uint8)\n",
    "            for i, row in enumerate(subarray):\n",
    "                for j, val in enumerate(row):\n",
    "                    binary_array[val, i * subarray.shape[1] + j] = 1\n",
    "            binary_arrays.append(binary_array)\n",
    "        return np.array(binary_arrays)\n",
    "    \n",
    "    @staticmethod\n",
    "    def informativeness(L):\n",
    "        inf_arrays = []\n",
    "        for subarray in L:\n",
    "            unique_labels = np.unique(subarray)\n",
    "            inf_p = np.zeros((len(unique_labels), subarray.size))\n",
    "            for c in unique_labels:\n",
    "                coords = np.argwhere(subarray == c)\n",
    "                for i, m in enumerate(list(np.ndindex(subarray.shape))):\n",
    "                    for n in coords:\n",
    "                        inf_p[c, i] += distance.euclidean(m, n)\n",
    "            inf_arrays.append(inf_p)\n",
    "        return np.array(inf_arrays)\n",
    "\n",
    "    def L_0(self, L):\n",
    "        '''Literal listener'''\n",
    "        binary_lang = self.binary_language(L)\n",
    "        return self.normalize(binary_lang * self.prior * self.informativeness(L))\n",
    "    \n",
    "    def S_p(self, L):\n",
    "        return self.normalize(np.exp(self.alpha * (self.safelog(self.L_0(L).transpose(0, 2, 1)))))\n",
    "    \n",
    "    def L_p(self, L):\n",
    "        return self.normalize((self.S_p(L).transpose(0, 2, 1) * self.prior * self.informativeness(L)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = BaseRSA(1, np.ones(4) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = generate_lexicons(2, (2, 2), 2)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.41421356, 1.        ],\n",
       "       [2.41421356, 3.41421356, 2.        , 2.41421356]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.informativeness(L)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5       , 0.5       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.5       , 0.5       ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.35355339, 0.        , 0.29289322, 0.35355339]]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.L_p(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "class BaseRSA:\n",
    "    def __init__(self, alpha, prior):\n",
    "        self.alpha = alpha\n",
    "        self.prior = prior\n",
    "\n",
    "    @staticmethod\n",
    "    def safelog(vals):\n",
    "        with np.errstate(divide='ignore'):\n",
    "            return np.log(vals)\n",
    "        \n",
    "    @staticmethod\n",
    "    def binary_language(L):\n",
    "        max_labels = np.max([np.max(subarray) for subarray in L]) + 1\n",
    "        binary_arrays = []\n",
    "        for subarray in L:\n",
    "            x = max_labels\n",
    "            y = np.prod(subarray.shape)\n",
    "            binary_array = np.zeros((x, y), dtype=np.uint8)\n",
    "            for i, row in enumerate(subarray):\n",
    "                for j, val in enumerate(row):\n",
    "                    binary_array[val, i * subarray.shape[1] + j] = 1\n",
    "            binary_arrays.append(binary_array)\n",
    "        return np.array(binary_arrays)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(vals):\n",
    "        return np.nan_to_num(vals / np.sum(vals, axis=-1, keepdims=True))\n",
    "    \n",
    "    @staticmethod\n",
    "    def informativeness(L):\n",
    "        inf_arrays = []\n",
    "        for subarray in L:\n",
    "            inf_p = np.zeros(subarray.shape)\n",
    "            unique_labels = np.unique(subarray)\n",
    "            for c in unique_labels:\n",
    "                coords = np.argwhere(subarray == c)\n",
    "                for m in list(np.ndindex(subarray.shape)):\n",
    "                    for n in coords:\n",
    "                        inf_p[m[0], m[1]] += distance.euclidean(m, n)\n",
    "            inf_arrays.append(inf_p.flatten())\n",
    "        return np.expand_dims(np.array(inf_arrays), axis=1)\n",
    "\n",
    "    def L_0(self, L):\n",
    "        '''Literal listener'''\n",
    "        return self.normalize(self.binary_language(L) * self.informativeness(L) * self.prior) \n",
    "    # \n",
    "    \n",
    "    def S_p(self, L):\n",
    "        return self.normalize(np.exp(self.alpha * (self.safelog(self.L_0(L).transpose(0, 2, 1)))))\n",
    "    \n",
    "    def L_p(self, L):\n",
    "        return self.normalize((self.S_p(L).transpose(0, 2, 1) * self.prior))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = generate_lexicons(2, (2, 2), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[0, 1],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 0]]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa = BaseRSA(10, np.ones(4) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "\n",
       "       [[0.5       , 0.        , 0.        , 0.5       ],\n",
       "        [0.        , 0.5       , 0.5       , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "        [1.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.5       , 0.        , 0.5       ],\n",
       "        [0.5       , 0.        , 0.5       , 0.        ]],\n",
       "\n",
       "       [[0.33333333, 0.33333333, 0.        , 0.33333333],\n",
       "        [0.        , 0.        , 1.        , 0.        ]]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsa.L_p(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseRSA):\n",
    "    def __init__(self, alpha, prior, N, shape, n):\n",
    "        super().__init__(alpha, prior)\n",
    "        self.Lexicons = generate_lexicons(N=N, shape=shape, n=n)\n",
    "        self.prob_lexicon = np.ones(len(self.Lexicons)) / len(self.Lexicons)\n",
    "        self.n_words = N\n",
    "        self.n_meanings = shape[0] * shape[1]\n",
    "\n",
    "        self.degree_of_convexity = self.normalize(degree_of_convexity(self.Lexicons))\n",
    "    \n",
    "    def speaker(self, m):\n",
    "        lexicon_idx = np.random.choice(np.arange(len(self.Lexicons)), p=self.prob_lexicon)\n",
    "        # print(self.S_p(self.Lexicons)[lexicon_idx][m,:])\n",
    "        # return self.S_p(self.Lexicons, c)[lexicon_idx][m].argmax()\n",
    "        return np.random.choice(np.arange(self.n_words), p=self.S_p(self.Lexicons)[lexicon_idx][m])\n",
    "    \n",
    "    def listener(self, w):\n",
    "        # index of the lexicon with the highest probability given prob_lexicon\n",
    "        lexicon_idx = np.random.choice(np.arange(len(self.Lexicons)), p=self.prob_lexicon)\n",
    "        if np.sum(self.L_p(self.Lexicons)[lexicon_idx][w]) < 1:\n",
    "            return np.random.choice(np.arange(self.n_meanings), p=[1 / self.n_meanings] * self.n_meanings)\n",
    "        else:\n",
    "            return np.random.choice(np.arange(self.n_meanings), p=self.L_p(self.Lexicons)[lexicon_idx][w])\n",
    "\n",
    "    def update(self, w, m, correct, role):\n",
    "        # self.prob_lexicon = self.normalize((self.degree_of_convexity ** 1/0.1) * self.prob_lexicon + NOISE)\n",
    "        if role == \"speaker\":\n",
    "            if correct:\n",
    "                self.prob_lexicon = self.normalize(self.S_p(self.Lexicons)[:, m, w] * self.prob_lexicon + NOISE)\n",
    "            else:\n",
    "                self.prob_lexicon = self.normalize(self.S_p(self.Lexicons)[:, m, 1 - w] * self.prob_lexicon + NOISE)\n",
    "        elif role == \"listener\":\n",
    "            if correct:\n",
    "                self.prob_lexicon = self.normalize(self.L_p(self.Lexicons)[:, w, m] \n",
    "                * self.prob_lexicon + NOISE)\n",
    "            else:\n",
    "                meanings = range(self.n_meanings)\n",
    "                for meaning in meanings:\n",
    "                    if meaning != m:\n",
    "                        self.prob_lexicon = self.normalize(self.L_p(self.Lexicons)[:, w, meaning]\n",
    "                        * self.prob_lexicon + NOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 values with equal probability\n",
    "prior = np.ones(4) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(alpha=1, prior=prior, N=2, shape=(2, 2), n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.speaker(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, alpha, prior, shape, n, n_iter, n_rounds, N):\n",
    "        self.n_iter = n_iter\n",
    "        self.n_rounds = n_rounds\n",
    "\n",
    "        self.logs = defaultdict(lambda: defaultdict(dict))\n",
    "        \n",
    "        self.group_posterior = []\n",
    "        self.lexicons = []\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.prior = prior\n",
    "\n",
    "        self.shape = shape\n",
    "        self.n = n\n",
    "        self.N = N\n",
    "\n",
    "    def sample_meaning(self):\n",
    "        return np.random.choice([i for i in range(self.shape[0] * self.shape[1])])\n",
    "\n",
    "    def one_round(self, a, b, m, i, r):\n",
    "        w = a.speaker(m)\n",
    "        g = b.listener(w)\n",
    "\n",
    "        a.update(w, m, m == g, \"speaker\")\n",
    "        b.update(w, m, m == g, \"listener\")\n",
    "\n",
    "        self.logs[i][r]['word'] = w\n",
    "        self.logs[i][r]['guess'] = g\n",
    "        self.logs[i][r]['correct'] = 1 if (m == g) else 0\n",
    "    \n",
    "    def run(self):\n",
    "        for i in range(self.n_iter):\n",
    "            agents = [Agent(alpha=self.alpha, prior=self.prior, N=self.N, shape=self.shape, n=self.n),\n",
    "                      Agent(alpha=self.alpha, prior=self.prior, N=self.N, shape=self.shape, n=self.n)]\n",
    "\n",
    "            for r in range(self.n_rounds):\n",
    "                m = self.sample_meaning()\n",
    "                self.logs[i][r]['meaning'] = m\n",
    "                if r % 2 == 0:\n",
    "                    self.one_round(agents[0], \n",
    "                                   agents[1], \n",
    "                                   m, i, r)\n",
    "                else:\n",
    "                    self.one_round(agents[1], \n",
    "                                   agents[0], \n",
    "                                    m, i, r)\n",
    "            \n",
    "            self.group_posterior.append(agents[0].prob_lexicon)\n",
    "            self.group_posterior.append(agents[1].prob_lexicon)\n",
    "\n",
    "            self.lexicons.append(agents[0].Lexicons)\n",
    "            self.lexicons.append(agents[1].Lexicons)\n",
    "    \n",
    "                        \n",
    "    def save(self, rd=False):\n",
    "        df = pd.DataFrame.from_dict({(i, r): self.logs[i][r]\n",
    "                                        for i in self.logs.keys()\n",
    "                                        for r in self.logs[i].keys()},\n",
    "                                        orient='index').reset_index()\n",
    "        df.columns = ['trial', 'round', 'meaning', 'word',\n",
    "                      'guess', 'correct']\n",
    "        if not rd:\n",
    "            df.to_csv(f'src/data/logs/logs-{self.n_iter}-{self.model}-{self.n_rounds}.csv', index=False)\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Experiment(alpha=1, \n",
    "               shape=(3, 3), \n",
    "               n=100, \n",
    "               n_iter=1, \n",
    "               n_rounds=50,\n",
    "               prior= np.ones(9) / 9, \n",
    "               N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a.save(rd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_correct'] = df.groupby('trial')['correct'].rolling(5).mean().reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot rolling mean \n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "sns.lineplot(data=df, x='round', y='rolling_correct')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_upper_bound(4, (3, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
